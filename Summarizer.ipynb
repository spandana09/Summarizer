{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bekirId8kf6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "#scraping the data\n",
        "url = 'https://en.wikipedia.org/wiki/Artificial_intelligence'\n",
        "response = requests.get(url)\n",
        "\n",
        "#parsing the data\n",
        "parsed_article = BeautifulSoup(response.text,'lxml')\n",
        "\n",
        "# retrieving the paragraphs in the article\n",
        "paragraphs = parsed_article.find_all('p') \n",
        "\n",
        "article_text = \"\"\n",
        "\n",
        "#combining all the paragraphs\n",
        "for p in paragraphs:\n",
        "    article_text += p.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ8AQ3TmknGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing the square brackets and extra spaces\n",
        "import re\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-PXEao4kw-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing special characters and digits\n",
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6blSEIqk21w",
        "colab_type": "code",
        "outputId": "f6614072-f38c-40c7-c972-8554aeb4434b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#sentence tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "sentence_list = nltk.sent_tokenize(article_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PmYDlWlBKX",
        "colab_type": "code",
        "outputId": "a506909b-96a5-45dd-c333-9fd7836e364b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "#storing all the stopwords \n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "#finding frequency of occurence of each word\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLVaMokmpCBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding weighted fequency\n",
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nov7Zy_zpLdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating sentence scores\n",
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_94ZiBsrpQIL",
        "colab_type": "code",
        "outputId": "e92c2078-8b68-44ff-f057-fdeaf7312d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#retrieving the sentences\n",
        "import heapq\n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans. Artificial intelligence can be classified into three different types of systems: analytical, human-inspired, and humanized artificial intelligence. Neural networks can be applied to the problem of intelligent control (for robotics) or learning, using such techniques as Hebbian learning (\"fire together, wire together\"), GMDH or competitive learning. Musk also funds companies developing artificial intelligence such as Google DeepMind and Vicarious to \"just keep an eye on what's going on with artificial intelligence. IBM has created its own artificial intelligence computer, the IBM Watson, which has beaten human intelligence (at some levels). Many of the problems in this article may also require general intelligence, if machines are to solve the problems as well as people do. \"robotics\" or \"machine learning\"), the use of particular tools (\"logic\" or artificial neural networks), or deep philosophical differences.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}